# Taller ‚Äî Desarrollo en Contenedores (API + Jupyter + MLFlow + Docker Compose + Mino)

Este proyecto tiene como objetivo implementar una arquitectura MLOps h√≠brida que permite desplegar y gestionar un flujo completo de Machine Learning utilizando MLflow como herramienta central de tracking y versionado de modelos. La soluci√≥n integra m√∫ltiples servicios mediante contenedores orquestados con Docker Compose, optimizando tanto el desarrollo local como el despliegue en entornos productivos.

### Estructura de Archivos

üìÅ taller4/
‚îú‚îÄ‚îÄ üìÅ api/
‚îÇ ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ ‚îî‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ üìÅ mlflow/
‚îÇ ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ ‚îú‚îÄ‚îÄ data_ingestion.py
‚îÇ ‚îú‚îÄ‚îÄ docker-compose.yml
‚îÇ ‚îú‚îÄ‚îÄ docker-compose.yml.bak
‚îî‚îÄ‚îÄ README.md

### Servios

| Servicio          | Imagen / Build                  | Puerto(s)      | Descripci√≥n                                                              |
| ----------------- | ------------------------------- | -------------- | ------------------------------------------------------------------------ |
| **MinIO**         | `quay.io/minio/minio:latest`    | `9000`, `9001` | Almacenamiento de artefactos S3-compatible.                              |
| **MySQL**         | `mysql:8.0`                     | `3306`         | Almac√©n de datos de entrenamiento y aplicaci√≥n. Backend store de MLflow. |
| **MLflow**        | `./mlflow/Dockerfile`           | `5000`         | Tracking y registro de modelos. Integrado con MinIO y MySQL.             |
| **Jupyter**       | `jupyter/scipy-notebook:latest` | `8888`         | Entorno de desarrollo con conexi√≥n a MLflow, MinIO y MySQL.              |
| **API (FastAPI)** | `./api/Dockerfile`              | `8000`         | Servicio de inferencia que consume modelos del MLflow Registry.          |


Levantar los servicios que esten funcionales:
### Imagen 1 docker compose

### Vol√∫menes

| Volumen      | Descripci√≥n                                  |
| ------------ | -------------------------------------------- |
| `minio_data` | Persiste los datos almacenados en MinIO      |
| `mysql_data` | Persiste los datos de la base de datos MySQL |


### Dependencias

* MLflow depende de que MinIO y MySQL est√©n activos.
* Jupyter y API requieren de MLflow para funcionar correctamente.
* Todos los servicios comparten credenciales de acceso a MinIO

### Ejecuci√≥n

#### Script de Ingesta de Datos

Archivo: mlflow/data_ingestion.py

El script se ejecuta fuera de los contenedores para insertar datos en MySQL. Crea autom√°ticamente la base penguins_db, carga el dataset y realiza preprocesamiento b√°sico.

Puedes ejecutarlo as√≠:
export DATA_DB_URI="mysql+pymysql://mlflow_user:mlflow_pass@localhost:3306/penguins_db"
python mlflow/data_ingestion.py

#### API FastAPI para Inferencia

Archivo: api/app.py
Sirve el modelo en producci√≥n usando mlflow.pyfunc, con validaci√≥n de esquema y coerci√≥n de tipos. Endpoints disponibles:

* GET /health
* GET /input-schema
* POST /predict
* POST /reload-model

#### Entrenamiento del Modelo

Abre Jupyter:
http://localhost:8888/?token=valentasecret

* Ejecuta el notebook en la carpeta notebooks/ para:
* Cargar los datos
* Entrenar modelos con GridSearch
* Registrar el mejor modelo en MLflow
* Promoverlo a Producci√≥n

### IMAGEN MLFLOW

#### Prueba de Inferencia

Con el API de FastAPI corriendo:
Consulta el esquema:
curl http://localhost:8000/input-schema

Realiza posteriormente una predicci√≥n:
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"dataframe_split": {"columns": [...], "data": [[...]]}}'

