{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7194a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "import os\n",
    "import json\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Dentro de Docker, servicios hablan por hostname del servicio: mlflow\n",
    "TRACKING_URI_DOCKER = \"http://mlflow:5000\"\n",
    "mlflow.set_tracking_uri(TRACKING_URI_DOCKER)\n",
    "\n",
    "# Para abrir la UI desde el host:\n",
    "MLFLOW_UI_HOST = \"http://localhost:5002\"  # host:5002 -> container:5000\n",
    "\n",
    "EXPERIMENT_NAME = \"penguins_gridsearch_v1\"\n",
    "REGISTERED_MODEL_NAME = \"PenguinClassifier\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "print(\"MLflow tracking   :\", mlflow.get_tracking_uri())\n",
    "print(\"MLflow UI (host)  :\", MLFLOW_UI_HOST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c09d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Conexión a MySQL dentro de Docker\n",
    "DATA_DB_URI = \"mysql+pymysql://mlflow_user:mlflow_pass@mysql:3306/penguins_db\"\n",
    "engine = create_engine(DATA_DB_URI)\n",
    "\n",
    "RAW_SCHEMA, PROC_SCHEMA = \"raw\", \"processed\"\n",
    "RAW_TABLE, PROC_TABLE = \"penguins_raw\", \"penguins_processed\"\n",
    "\n",
    "def table_exists(engine, schema, table):\n",
    "    with engine.connect() as con:\n",
    "        q = text(\"\"\"\n",
    "            SELECT COUNT(*)\n",
    "            FROM information_schema.tables\n",
    "            WHERE table_schema=:schema AND table_name=:table\n",
    "        \"\"\")\n",
    "        return con.execute(q, {\"schema\": schema, \"table\": table}).scalar() > 0\n",
    "\n",
    "if table_exists(engine, PROC_SCHEMA, PROC_TABLE):\n",
    "    df = pd.read_sql_table(PROC_TABLE, con=engine, schema=PROC_SCHEMA)\n",
    "    print(f\"Cargado desde MySQL: {PROC_SCHEMA}.{PROC_TABLE} -> {df.shape}\")\n",
    "else:\n",
    "    # Fallback: construimos el procesado\n",
    "    print(\"No existe processed.penguins_processed; creando fallback en memoria…\")\n",
    "    from palmerpenguins import load_penguins\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "    import numpy as np\n",
    "\n",
    "    raw = load_penguins()\n",
    "    LABEL_COL = \"species\"\n",
    "    NUMERIC_COLS = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'year']\n",
    "    CATEGORICAL_COLS = ['island', 'sex']\n",
    "\n",
    "    # Split\n",
    "    y = raw[LABEL_COL]\n",
    "    X = raw.drop(columns=[LABEL_COL], errors='ignore').copy()\n",
    "\n",
    "    # Numeric → coerce + impute + scale\n",
    "    for c in NUMERIC_COLS:\n",
    "        X[c] = pd.to_numeric(X[c], errors='coerce')\n",
    "    num_imputer = SimpleImputer(strategy=\"median\")\n",
    "    X_num = num_imputer.fit_transform(X[NUMERIC_COLS])\n",
    "    num_scaler = StandardScaler()\n",
    "    X_num = num_scaler.fit_transform(X_num)\n",
    "\n",
    "    # Categorical → fill + OHE\n",
    "    cats = X[CATEGORICAL_COLS].astype('string').fillna('missing')\n",
    "    # Nota: 'sparse_output' requiere scikit-learn >= 1.2; en versiones previas usa 'sparse=False'\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    X_cat = ohe.fit_transform(cats)\n",
    "\n",
    "    # Concatenate\n",
    "    try:\n",
    "        cat_names = list(ohe.get_feature_names_out(CATEGORICAL_COLS))\n",
    "    except Exception:\n",
    "        cat_names = [f\"cat_{i}\" for i in range(X_cat.shape[1])]\n",
    "    feature_names = NUMERIC_COLS + cat_names\n",
    "    Xp = np.hstack([X_num, X_cat])\n",
    "    df = pd.DataFrame(Xp, columns=feature_names)\n",
    "    df[LABEL_COL] = y.values\n",
    "    print(\"Procesado en memoria:\", df.shape, \"→ columnas:\", df.columns.tolist())\n",
    "\n",
    "# División train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "LABEL_COL = \"species\"\n",
    "X = df.drop(columns=[LABEL_COL])\n",
    "y = df[LABEL_COL]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=42, test_size=0.2\n",
    ")\n",
    "print(\"Train/Test shapes:\", X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9250f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Dos modelos en pipeline para garantizar ≥ 20 ejecuciones\n",
    "# 1) LogisticRegression (varias Cs y penalties)\n",
    "# 2) RandomForest (varias profundidades y estimadores)\n",
    "pipelines = {\n",
    "    \"logreg\": Pipeline(steps=[\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),  # X ya viene escalado; seguridad por si acaso\n",
    "        (\"clf\", LogisticRegression(max_iter=1000))\n",
    "    ]),\n",
    "    \"rf\": Pipeline(steps=[\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),\n",
    "        (\"clf\", RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    \"logreg\": {\n",
    "        \"clf__C\": [0.1, 0.3, 1.0, 3.0, 10.0],\n",
    "        \"clf__penalty\": [\"l2\"],  # l1 exigiría solver diferente\n",
    "        \"clf__solver\": [\"lbfgs\", \"liblinear\"],  # 5*1*2 = 10\n",
    "    },\n",
    "    \"rf\": {\n",
    "        \"clf__n_estimators\": [50, 100, 150],     # 3\n",
    "        \"clf__max_depth\": [3, 5, 8, None],       # 4\n",
    "        \"clf__min_samples_split\": [2, 4],        # 2 -> 3*4*2 = 24 combinaciones\n",
    "    },\n",
    "}\n",
    "\n",
    "# Autolog\n",
    "mlflow.sklearn.autolog(\n",
    "    log_model_signatures=True,\n",
    "    log_input_examples=True,\n",
    "    log_models=True\n",
    ")\n",
    "\n",
    "results = []\n",
    "for name, pipe in pipelines.items():\n",
    "    grid = GridSearchCV(pipe, param_grids[name], cv=3, n_jobs=2, verbose=0)\n",
    "    with mlflow.start_run(run_name=f\"gridsearch_{name}\") as run:\n",
    "        grid.fit(X_train, y_train)\n",
    "        best_est = grid.best_estimator_\n",
    "        best_score = grid.best_score_\n",
    "        # Log extra metrics manuales\n",
    "        mlflow.log_metric(\"cv_best_score\", float(best_score))\n",
    "        mlflow.set_tag(\"model_family\", name)\n",
    "        results.append({\n",
    "            \"name\": name,\n",
    "            \"best_score\": best_score,\n",
    "            \"best_estimator\": best_est,\n",
    "            \"run_id\": run.info.run_id\n",
    "        })\n",
    "\n",
    "len(results), results[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7710d805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# Elegimos el mejor por cv_best_score\n",
    "best_entry = max(results, key=lambda r: r[\"best_score\"])\n",
    "best_name = best_entry[\"name\"]\n",
    "best_est = best_entry[\"best_estimator\"]\n",
    "best_entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aea12d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "with mlflow.start_run(run_name=f\"register_best_{best_name}\") as run:\n",
    "    # Entrenamos con train completo para registrar \"el\" modelo\n",
    "    best_est.fit(X_train, y_train)\n",
    "    y_pred = best_est.predict(X_test)\n",
    "    acc_test = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy_test\", float(acc_test))\n",
    "\n",
    "    # Log del modelo como artefacto estándar (y registro de modelo)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=best_est,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=REGISTERED_MODEL_NAME\n",
    "    )\n",
    "\n",
    "    client = MlflowClient()\n",
    "    # Obtenemos la última versión creada por este run\n",
    "    mv = client.get_latest_versions(REGISTERED_MODEL_NAME, stages=[])\n",
    "    # Ordenamos por versión y nos quedamos la última\n",
    "    mv = sorted(mv, key=lambda m: int(m.version))[-1]\n",
    "    print(\"Registered:\", mv.name, \"version:\", mv.version)\n",
    "\n",
    "    # Promover a Production\n",
    "    client.transition_model_version_stage(\n",
    "        name=mv.name, version=mv.version, stage=\"Production\", archive_existing_versions=True\n",
    "    )\n",
    "    print(\"Promoted to Production:\", mv.name, \"version:\", mv.version, \"→ ver en UI\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "from urllib.parse import quote\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "exps = client.search_experiments()\n",
    "print(\"Experimentos:\", [e.name for e in exps])\n",
    "\n",
    "# Link a la UI (host)\n",
    "print(\"MLflow UI (host):\", MLFLOW_UI_HOST)\n",
    "\n",
    "# Link directo al experimento\n",
    "exp = [e for e in exps if e.name == EXPERIMENT_NAME][0]\n",
    "print(\"Experimento en host:\", f\"{MLFLOW_UI_HOST}/#/experiments/{exp.experiment_id}\")\n",
    "\n",
    "# Link a los modelos registrados\n",
    "print(\"Model Registry:\", f\"{MLFLOW_UI_HOST}/#/models/{quote(REGISTERED_MODEL_NAME)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a6bab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "import mlflow.pyfunc\n",
    "import pandas as pd\n",
    "\n",
    "model = mlflow.pyfunc.load_model(f\"models:/{REGISTERED_MODEL_NAME}/Production\")\n",
    "\n",
    "# Construimos un ejemplo con el esquema en API\n",
    "example = pd.DataFrame([{\n",
    "    \"bill_length_mm\": 39.5,\n",
    "    \"bill_depth_mm\": 17.4,\n",
    "    \"flipper_length_mm\": 186.0,\n",
    "    \"body_mass_g\": 3800.0,\n",
    "    \"year\": 2007.0,\n",
    "    \"island_Biscoe\": 0.0,\n",
    "    \"island_Dream\": 1.0,\n",
    "    \"island_Torgersen\": 0.0,\n",
    "    \"sex_female\": 1.0,\n",
    "    \"sex_male\": 0.0,\n",
    "    \"sex_missing\": 0.0\n",
    "}])\n",
    "\n",
    "pred = model.predict(example)\n",
    "print(pred)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
