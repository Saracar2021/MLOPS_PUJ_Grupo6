# MLOps Proyecto 2 - Sistema de PredicciÃ³n de Cobertura Forestal
## Grupo 6 - Pontificia Universidad Javeriana

## ğŸ“‹ DescripciÃ³n del Proyecto

Sistema completo de MLOps que implementa un pipeline de entrenamiento y predicciÃ³n para clasificaciÃ³n de tipos de cobertura forestal (Forest Cover Type). El sistema utiliza:

- **Airflow**: OrquestaciÃ³n de pipelines de entrenamiento
- **MLflow**: Registro de experimentos y modelos
- **MinIO**: Almacenamiento de artefactos
- **MySQL**: Base de datos de metadata
- **FastAPI**: API de inferencia
- **Streamlit**: Interfaz grÃ¡fica (BONO)

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Docker Compose                         â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Airflow  â”‚â†’ â”‚ MLflow  â”‚â†’ â”‚ MinIO  â”‚  â”‚  MySQL   â”‚  â”‚
â”‚  â”‚   DAG    â”‚  â”‚Tracking â”‚  â”‚ S3     â”‚  â”‚Metadata  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚             â”‚                                   â”‚
â”‚       â†“             â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚Data API  â”‚  â”‚  FastAPI    â”‚â† Puerto 8989           â”‚
â”‚  â”‚External  â”‚  â”‚  Inference  â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚  â”‚   Streamlit UI   â”‚â† Puerto 8503 (BONO)             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Estructura del Proyecto

```
Proyecto2/
â”œâ”€â”€ docker-compose.yml         # OrquestaciÃ³n de servicios
â”œâ”€â”€ .env                       # Variables de entorno
â”œâ”€â”€ README.md                  # Este archivo
â”‚
â”œâ”€â”€ airflow/                   # Servicio Airflow
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ training_pipeline.py
â”‚
â”œâ”€â”€ mlflow/                    # Servicio MLflow
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ inference_api/             # API de Inferencia
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ data_api/                  # API de Datos (del profesor)
â”‚   â””â”€â”€ (cÃ³digo del repositorio del profesor)
â”‚
â””â”€â”€ ui/                        # Interfaz GrÃ¡fica (BONO)
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ app.py
    â””â”€â”€ requirements.txt
```

## ğŸš€ Instrucciones de InstalaciÃ³n

### Prerequisitos

- Docker Desktop instalado y corriendo
- Docker Compose v2.0+
- Git
- Al menos 8GB de RAM disponible
- 20GB de espacio en disco

### Paso 1: Clonar el Repositorio

```bash
# Clonar el repositorio del grupo
git clone https://github.com/Saracar2021/MLOPS_PUJ_Grupo6.git
cd MLOPS_PUJ_Grupo6

# Crear carpeta del proyecto
mkdir -p Proyecto2
cd Proyecto2
```

### Paso 2: Clonar la API de Datos del Profesor - NO SE NECESITA PORQUE SE VA A CORRER APUNTANDO A LA http://10.43.100.103:8080

```bash
# Clonar la API de datos en la carpeta data_api
git clone https://github.com/CristianDiazAlvarez/MLOPS_PUJ.git temp_mlops
cp -r temp_mlops/Niveles/2/P2/* data_api/
rm -rf temp_mlops
```

### Paso 3: Crear la Estructura de Carpetas

```bash
# Crear todas las carpetas necesarias
mkdir -p airflow/dags airflow/logs airflow/plugins
mkdir -p mlflow
mkdir -p inference_api
mkdir -p ui
```

### Paso 5: Configurar Variables de Entorno

Crea el archivo `.env` en la raÃ­z del proyecto:

```bash
# MySQL
MYSQL_ROOT_PASSWORD=rootpassword
MYSQL_DATABASE=mlflow_db
MYSQL_USER=mlflow_user
MYSQL_PASSWORD=mlflow_password

# MinIO
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin
MINIO_BUCKET=mlflow

# MLflow
MLFLOW_TRACKING_URI=http://mlflow:5000
MLFLOW_S3_ENDPOINT_URL=http://minio:9000

# API Externa (modificar segÃºn necesidad)
#DATA_API_URL=http://data_api:8080
DATA_API_URL=http://10.43.100.103:8080
GROUP_NUMBER=6

# Airflow
AIRFLOW_UID=50000
```

### Paso 6: Construir y Levantar los Servicios

```bash
# Construir todas las imÃ¡genes
docker-compose build

# Levantar todos los servicios
docker-compose up -d

# Ver logs de todos los servicios
docker-compose logs -f

# Ver logs de un servicio especÃ­fico
docker-compose logs -f mlflow
```

### Paso 7: Verificar que los Servicios EstÃ©n Corriendo

```bash
# Ver estado de los contenedores
docker-compose ps

# Todos los servicios deben mostrar estado "Up" o "healthy"
```

## ğŸŒ Acceso a los Servicios

Una vez que todos los servicios estÃ©n corriendo:

| Servicio | URL | Credenciales |
|----------|-----|--------------|
| **Airflow** | http://localhost:8080 | usuario: `admin` / password: `admin` |
| **MLflow** | http://localhost:5000 | Sin autenticaciÃ³n |
| **MinIO Console** | http://localhost:9001 | usuario: `minioadmin` / password: `minioadmin` |
| **Inference API** | http://localhost:8989 | Sin autenticaciÃ³n |
| **API Docs** | http://localhost:8989/docs | DocumentaciÃ³n interactiva |
| **Streamlit UI (BONO)** | http://localhost:8503 | Sin autenticaciÃ³n |

## ğŸ“Š Flujo de Trabajo

### 1. Entrenamiento de Modelos

1. Accede a Airflow: http://localhost:8080
2. Busca el DAG: `forest_cover_training_pipeline`
3. Activa el DAG (toggle en ON)
4. Ejecuta manualmente: Click en "Trigger DAG"
5. Monitorea la ejecuciÃ³n en tiempo real

El DAG ejecutarÃ¡:
- âœ… ObtenciÃ³n de datos de la API 
- âœ… Preprocesamiento de datos
- âœ… Entrenamiento de 3 modelos (Logistic Regression, Random Forest, Gradient Boosting)
- âœ… Registro en MLflow con mÃ©tricas y artefactos

### 2. RevisiÃ³n de Experimentos

1. Accede a MLflow: http://localhost:5000
2. Selecciona el experimento: `forest_cover_classification`
3. Compara mÃ©tricas entre modelos
4. Revisa artefactos y parÃ¡metros

### 3. Realizar Predicciones

#### OpciÃ³n A: Usando la API Directamente

```bash
# Listar modelos disponibles
curl http://localhost:8989/models

# Cargar un modelo especÃ­fico
curl -X POST "http://localhost:8989/models/forest_cover_random_forest/load?stage=Production"

# Realizar predicciÃ³ni
curl -X POST "http://localhost:8989/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "Elevation": 2596,
    "Aspect": 51,
    "Slope": 3,
    "Horizontal_Distance_To_Hydrology": 258,
    "Vertical_Distance_To_Hydrology": 0,
    "Horizontal_Distance_To_Roadways": 510,
    "Hillshade_9am": 221,
    "Hillshade_Noon": 232,
    "Hillshade_3pm": 148,
    "Horizontal_Distance_To_Fire_Points": 6279,
    "Wilderness_Area": "Rawah",
    "Soil_Type": "C7744"
  }'

```

#### OpciÃ³n B: Usando la Interfaz de Streamlit (BONO) -- PENDIENTE PORQUE AÃšN EL BONO NO ME ACABA DE FUNCIONAR

1. Accede a: http://localhost:8503
2. Navega a "PredicciÃ³n Individual"
3. Ingresa los datos del Ã¡rea forestal
4. Haz clic en "Realizar PredicciÃ³n"

## ğŸ¯ Funcionalidades Implementadas

### âœ… Requerimientos Obligatorios

- [x] Docker Compose con todos los servicios
- [x] Airflow para orquestaciÃ³n
- [x] MLflow con registro de experimentos
- [x] MinIO como object storage
- [x] MySQL para metadata
- [x] API de inferencia con FastAPI (puerto 8989)
- [x] Entrenamiento de mÃºltiples modelos
- [x] Pipeline automatizado completo
- [x] DocumentaciÃ³n completa

### â­ BONO Implementado

- [x] **SelecciÃ³n de modelo en API**: Endpoint `/models/{model_name}/load` permite cambiar entre modelos
- [x] **Interfaz grÃ¡fica con Streamlit**: UI completa en puerto 8503
- [x] **PredicciÃ³n por lote**: Procesamiento de archivos CSV
- [x] **GestiÃ³n visual de modelos**: Interfaz para cargar y cambiar modelos

## ğŸ› ï¸ Comandos Ãštiles

```bash
# Detener todos los servicios
docker-compose down

# Detener y eliminar volÃºmenes (CUIDADO: elimina datos)
docker-compose down -v

# Reiniciar un servicio especÃ­fico
docker-compose restart airflow-webserver

# Ver logs en tiempo real
docker-compose logs -f

# Ejecutar comando dentro de un contenedor
docker-compose exec airflow-webserver bash

# Ver recursos utilizados
docker stats

# Limpiar todo (imÃ¡genes, contenedores, volÃºmenes)
docker system prune -a --volumes
```

## ğŸ”§ Troubleshooting

### Error: Puerto ya en uso

```bash
# Ver quÃ© proceso estÃ¡ usando el puerto
lsof -i :8080  # o el puerto que estÃ© en conflicto

# Matar el proceso
kill -9 <PID>
```

### Error: Contenedor no levanta

```bash
# Ver logs especÃ­ficos
docker-compose logs nombre_servicio

# Verificar configuraciÃ³n
docker-compose config
```

### Error: MLflow no conecta con MinIO

```bash
# Verificar que MinIO estÃ© corriendo
docker-compose ps minio

# Reiniciar MLflow
docker-compose restart mlflow
```

### Error: Airflow no puede conectar con MLflow

```bash
# Verificar red de Docker
docker network ls
docker network inspect proyecto2_mlops_network

# Reiniciar ambos servicios
docker-compose restart airflow-scheduler airflow-webserver mlflow
```

